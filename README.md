# ğŸŸ Voice2FishLog

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PyQt6](https://img.shields.io/badge/GUI-PyQt6-green.svg)](https://www.riverbankcomputing.com/software/pyqt/)

A professional desktop application for real-time speech-to-structured fish catch logging. Converts voice commands into structured entries (length in cm) using advanced speech recognition and natural language processing.

---

## ğŸ“‘ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage Guide](#-usage-guide)
- [Speech Recognition Engines](#-speech-recognition-engines)
- [Parser System](#-parser-system)
- [Noise Profiles](#-noise-profiles)
- [Evaluation Pipeline](#-evaluation-pipeline)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

Voice2FishLog enables fishery workers to log catch data hands-free through voice commands. The application processes natural speech like *"salmon twenty three point five"* and converts it to structured data entries with species identification and measurements in centimeters.

**Use Cases:**
- Commercial fishing vessels logging catch data
- Research vessels documenting marine life
- Fish markets recording inventory
- Aquaculture facilities tracking stock

**Technical Highlights:**
- **8 Speech Recognition Engines** - Multiple ASR backends for flexibility
- **Offline Capable** - Works without internet once models are cached
- **Real-time Processing** - WebRTC VAD + adaptive noise suppression
- **Robust Parsing** - Handles spelling variants, units, and natural speech patterns
- **Production Ready** - Comprehensive testing, evaluation pipeline, and error handling

---

## âœ¨ Key Features

### Speech Recognition
- ğŸ¤ **Multi-Engine Support**: faster-whisper (default), WhisperX, Vosk, Google Cloud Speech, Wav2Vec2, AssemblyAI, Gemini, Chirp
- ğŸ”‡ **Noise Suppression**: Adaptive noise reduction with configurable profiles
- ğŸ™ï¸ **Voice Activity Detection**: WebRTC VAD for intelligent audio segmentation
- ğŸ”Š **Audio Storage**: Optional segment saving for debugging and analysis

### Data Processing
- ğŸ  **Species Recognition**: Fuzzy matching for 100+ fish species with variant handling
- ğŸ“ **Measurement Parsing**: Robust number extraction supporting decimals and ranges
- ğŸ”„ **Unit Conversion**: Automatic conversion from various spoken units to cm
- âœï¸ **ASR Correction**: Post-recognition text correction for common errors
- ğŸŒ **Text Normalization**: Handles spelling variants, abbreviations, and colloquialisms

### User Interface
- ğŸ–¥ï¸ **PyQt6 GUI**: Modern, responsive desktop interface
- ğŸ“Š **Real-time Table**: Live data display with edit capabilities
- ğŸ“ˆ **Reports Tab**: Length distribution histograms and statistics
- âš™ï¸ **Settings Panel**: Engine selection, noise profiles, and configuration
- ğŸ”„ **Undo/Redo**: Full transaction history with rollback support
- ğŸ’¾ **Excel Export**: Automatic logging to .xlsx files

### Data Management
- ğŸ“ **Excel Logging**: Structured haul logs with automatic file management
- ğŸ“ **Session Logging**: Detailed session records with timestamps
- â˜ï¸ **Google Sheets Backup**: Optional cloud backup integration
- ğŸ”’ **Data Validation**: Input validation and error recovery

### Development & Testing
- âœ… **Comprehensive Tests**: Unit, integration, and end-to-end test coverage
- ğŸ“Š **Evaluation Pipeline**: Automated ASR engine benchmarking
- ğŸ¯ **Metrics Dashboard**: WER, CER, DER, exact match, and MAE metrics
- ğŸ”¬ **Production Replay**: Simulate real-world conditions in testing

---

## ğŸ—ï¸ Architecture

The application follows **Clean Architecture** principles with SOLID design patterns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Presentation Layer                 â”‚
â”‚  (PyQt6 GUI, MainWindow, Widgets, Event Handlers)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Application Layer                   â”‚
â”‚    (Use Cases, Services, Business Logic)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Domain Layer                      â”‚
â”‚  (Parser, Species Matcher, Number Parser)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Infrastructure Layer                  â”‚
â”‚ (Speech Recognizers, Config, Logger, Database)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Patterns Implemented

- **Dependency Injection**: Testable component composition
- **Factory Pattern**: Speech recognizer creation with registry
- **Strategy Pattern**: Pluggable parsing and matching algorithms
- **Facade Pattern**: Unified configuration and service interfaces
- **Observer Pattern**: Event-driven speech recognition callbacks
- **Singleton Pattern**: Session logger and application state management
- **Use Case Pattern**: Business logic isolation from UI

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11 or higher
- 4GB RAM minimum (8GB+ recommended for larger models)
- Microphone or audio input device

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd fish-logging

# Create virtual environment
python -m venv venv

# Activate virtual environment
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### First Run

```bash
# Launch application
python main.py
```

On first launch:
1. The default ASR model (faster-whisper base.en) will download automatically (~150MB)
2. The GUI will open with default settings
3. Grant microphone permissions when prompted
4. Click "Start Recording" and speak: *"salmon 23.5"*
5. See the parsed entry appear in the table

---

## ğŸ“¦ Installation

### Detailed Setup

#### 1. System Requirements

**Minimum:**
- Python 3.11+
- 4GB RAM
- 2GB disk space (for models)
- Microphone/audio input

**Recommended:**
- Python 3.11+
- 8GB+ RAM
- NVIDIA GPU with CUDA (for faster inference)
- Quality microphone with noise cancellation

#### 2. Virtual Environment Setup

```bash
# Create environment
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate

# Verify Python version
python --version  # Should be 3.11+
```

#### 3. Install Dependencies

```bash
# Core dependencies
pip install -r requirements.txt

# Optional: GPU acceleration (CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 4. Model Downloads

Models download automatically on first use. To pre-download:

```bash
# faster-whisper (default)
python -c "from faster_whisper import WhisperModel; WhisperModel('base.en', device='cpu')"

# Vosk (optional)
# Download from https://alphacephei.com/vosk/models
# Extract to ~/.cache/vosk/
```

#### 5. Configuration

```bash
# Copy example configuration (if provided)
cp .env.example .env

# Edit configuration
nano .env
```

#### 6. Verify Installation

```bash
# Run tests
python run_tests.py

# Launch application
python main.py
```

### Docker Installation (Alternative)

```bash
# Build image
docker build -t fish-logging .

# Run with audio device
docker run --device /dev/snd -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix fish-logging
```

---

## âš™ï¸ Configuration

### Configuration Files

All configuration files are located in the `config/` directory:

| File | Purpose | Required |
|------|---------|----------|
| `species.json` | Species lexicon with fuzzy matching aliases | âœ… Yes |
| `numbers.json` | Spoken number variants and mappings | âœ… Yes |
| `units.json` | Unit conversion rules (cm, inch, etc.) | âœ… Yes |
| `asr_corrections.json` | Post-ASR text corrections | âœ… Yes |
| `google_sheets.json` | Google Sheets backup credentials | â¬œ Optional |
| `user_settings.json` | User preferences (auto-generated) | â¬œ Optional |

### Species Configuration (`species.json`)

```json
{
  "salmon": {
    "scientific_name": "Salmo salar",
    "aliases": ["salman", "samon", "sammon", "atlantic salmon"],
    "category": "finfish"
  },
  "cod": {
    "scientific_name": "Gadus morhua",
    "aliases": ["atlantic cod", "cod fish", "court"],
    "category": "finfish"
  }
}
```

**Adding New Species:**
1. Add entry to `species.json`
2. Include common misspellings in `aliases`
3. Restart application

### Numbers Configuration (`numbers.json`)

```json
{
  "20": ["twenty", "20"],
  "21": ["twenty one", "twenty-one", "21"],
  "0.5": ["half", "point five", ".5"]
}
```

### ASR Corrections (`asr_corrections.json`)

```json
{
  "court": "cod",
  "salman": "salmon",
  "tree": "three",
  "to": "two"
}
```

### Environment Variables

Create a `.env` file for sensitive configuration:

```bash
# Speech Recognition API Keys
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
ASSEMBLYAI_API_KEY=your_api_key_here
GEMINI_API_KEY=your_api_key_here

# Application Settings
SPEECH_ENGINE=faster-whisper
NOISE_PROFILE=mixed
NUMBERS_ONLY=false

# Database
EXCEL_OUTPUT_PATH=logs/hauls/logs.xlsx
SESSION_LOG_DIR=logs/sessions

# Audio
SAVE_AUDIO_SEGMENTS=false
AUDIO_SEGMENTS_DIR=audio/segments
```

### Application Settings

Configure via GUI Settings tab or `config/user_settings.json`:

```json
{
  "speech": {
    "engine": "faster-whisper",
    "numbers_only": false,
    "language": "en",
    "noise_profile": "mixed"
  },
  "audio": {
    "save_segments": false,
    "segments_dir": "audio/segments"
  },
  "database": {
    "excel_output_path": "logs/hauls/logs.xlsx",
    "backup_enabled": true
  },
  "ui": {
    "theme": "default",
    "window_size": [1200, 800],
    "auto_save_interval": 30
  }
}
```

---

## ğŸ“– Usage Guide

### Basic Workflow

1. **Launch Application**
   ```bash
   python main.py
   ```

2. **Select ASR Engine** (Settings Tab)
   - Choose from dropdown: faster-whisper, whisperx, vosk, etc.
   - Configure noise profile based on environment

3. **Start Recording** (Main Tab)
   - Click "Start Recording" button
   - Status indicator shows "Listening..."

4. **Speak Entry**
   - Say: *"salmon twenty three point five"*
   - Or: *"cod 45 centimeters"*
   - Or: *"mackerel thirty to thirty five"*

5. **Review Entry**
   - Parsed entry appears in table
   - Edit if needed by double-clicking cells

6. **Save/Undo**
   - Entries auto-save to Excel
   - Use "Undo Last Entry" if needed

7. **View Reports** (Reports Tab)
   - Length distribution histograms
   - Species frequency charts
   - Session statistics

### Voice Commands

#### Fish Entry Patterns

```
Pattern: [species] [number] [optional_unit]

Examples:
âœ… "salmon 23.5"
âœ… "cod forty five centimeters"
âœ… "mackerel 30 to 35"
âœ… "haddock twenty three point five cm"
âœ… "tuna 120 santim"
```

#### Special Commands

```
âŒ "cancel" - Discards current entry
âŒ "undo" - Removes last saved entry
âŒ "clear" - Clears all entries (confirmation required)
```

### Number Recognition

The parser supports multiple spoken number formats:

```
Integers: "twenty three" â†’ 23
Decimals: "twenty three point five" â†’ 23.5
Ranges: "twenty to twenty five" â†’ "20-25"
Fractions: "twenty three and a half" â†’ 23.5
```

### Units Supported

```
Metric:
- cm, centimeter, centimetre, santim, santimetre
- m, meter, metre

Imperial:
- inch, inches, in
- foot, feet, ft
```

All measurements are converted to centimeters automatically.

### GUI Components

#### Main Tab
- **Transcription Panel**: Shows raw ASR output
- **Parsed Text Panel**: Displays normalized interpretation
- **Entry Table**: Live data with edit capability
- **Control Buttons**: Start/Stop, Undo, Clear
- **Status Bar**: Connection status and activity indicator

#### Settings Tab
- **ASR Engine**: Dropdown selection
- **Noise Profile**: clean/human/engine/mixed
- **Numbers Only Mode**: Toggle for numeric-only parsing
- **Audio Saving**: Enable segment capture for debugging

#### Reports Tab
- **Length Distribution**: Histogram by species
- **Species Frequency**: Pie chart of catches
- **Session Summary**: Count, avg, min, max statistics
- **Export**: Save reports as PNG/PDF

---

## ğŸ™ï¸ Speech Recognition Engines

### Engine Comparison

| Engine | Speed | Accuracy | Offline | GPU Support | Best For |
|--------|-------|----------|---------|-------------|----------|
| **faster-whisper** | â­â­â­â­ | â­â­â­â­â­ | âœ… Yes | âœ… Yes | Production (default) |
| **whisperx** | â­â­â­ | â­â­â­â­â­ | âœ… Yes | âœ… Yes | High accuracy needs |
| **vosk** | â­â­â­â­â­ | â­â­â­ | âœ… Yes | â¬œ No | Low resource devices |
| **wav2vec2** | â­â­â­ | â­â­â­â­ | âœ… Yes | âœ… Yes | Research/customization |
| **google** | â­â­â­â­ | â­â­â­â­â­ | â¬œ No | N/A | Cloud-based accuracy |
| **assemblyai** | â­â­â­â­ | â­â­â­â­ | â¬œ No | N/A | Streaming + features |
| **gemini** | â­â­â­ | â­â­â­â­â­ | â¬œ No | N/A | Multimodal context |
| **chirp** | â­â­â­â­ | â­â­â­â­â­ | â¬œ No | N/A | Low-resource languages |

### faster-whisper (Default)

**Setup:**
```python
# No setup needed - downloads automatically
# Model: base.en (~150MB)
```

**Advantages:**
- Excellent accuracy/speed balance
- Offline operation
- GPU acceleration
- Low memory footprint
- Production-ready

**Configuration:**
```python
# In settings or .env
SPEECH_ENGINE=faster-whisper
```

### WhisperX

**Setup:**
```bash
pip install whisperx
```

**Advantages:**
- Word-level timestamps
- Speaker diarization
- Highest accuracy
- Better alignment

**Use When:**
- Maximum accuracy needed
- Analyzing recorded audio
- Timestamp precision important

### Vosk

**Setup:**
```bash
pip install vosk
# Download model from https://alphacephei.com/vosk/models
# Extract to ~/.cache/vosk/
```

**Advantages:**
- Fastest inference
- Lowest resource usage
- Small model sizes (50MB)
- Works on Raspberry Pi

**Use When:**
- Limited hardware
- Embedded systems
- Speed over accuracy

### Google Cloud Speech

**Setup:**
```bash
# 1. Enable Cloud Speech-to-Text API in Google Cloud Console
# 2. Create service account and download JSON key
# 3. Set environment variable
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
```

**Advantages:**
- Industry-leading accuracy
- Automatic punctuation
- Profanity filtering
- 125+ languages

**Use When:**
- Internet available
- Accuracy is critical
- Budget for API costs (~$0.024/min)

### AssemblyAI

**Setup:**
```bash
# Get API key from https://www.assemblyai.com/
export ASSEMBLYAI_API_KEY=your_api_key
```

**Advantages:**
- Real-time streaming
- Speaker labels
- Content moderation
- Easy integration

### Gemini 2.5 Pro

**Setup:**
```bash
# Get API key from https://makersuite.google.com/
export GEMINI_API_KEY=your_api_key
```

**Advantages:**
- Multimodal understanding
- Context awareness
- Natural conversation

**Use When:**
- Complex queries
- Context important
- Multimodal input

### Wav2Vec2

**Setup:**
```bash
pip install transformers torch
```

**Advantages:**
- Self-supervised learning
- Fine-tunable
- Research-friendly
- Domain adaptation

**Use When:**
- Custom vocabulary
- Domain-specific terms
- Research projects

---

## ğŸ” Parser System

### Architecture

```
Input: "salmon twenty three point five cm"
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text Normalizer       â”‚ â† ASR corrections
â”‚   (asr_corrections.json)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
"salmon 23.5 cm"
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Species Matcher       â”‚ â† Species database
â”‚   (species.json)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
species: "salmon"
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Number Parser         â”‚ â† Number mappings
â”‚   (numbers.json)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
length: 23.5
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Unit Converter        â”‚ â† Unit definitions
â”‚   (units.json)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
Output: {species: "salmon", length_cm: 23.5}
```

### Species Matcher

**Strategies:**
1. **Exact Match**: Direct dictionary lookup
2. **Fuzzy Match**: Levenshtein distance (threshold: 85%)
3. **Alias Match**: Check predefined aliases

**Example:**
```python
Input: "salman"
Step 1: Exact match â†’ âŒ Not found
Step 2: Fuzzy match â†’ âœ… "salmon" (similarity: 87%)
Output: "salmon"
```

### Number Parser

**Strategies:**
1. **Word to Number**: "twenty three" â†’ 23
2. **Decimal Parsing**: "point five" â†’ 0.5
3. **Range Detection**: "20 to 25" â†’ "20-25"
4. **Fraction Handling**: "and a half" â†’ 0.5

**Examples:**
```python
"twenty three" â†’ 23
"twenty three point five" â†’ 23.5
"twenty to twenty five" â†’ "20-25"
"twenty three and a half" â†’ 23.5
```

### Text Normalizer

**Operations:**
1. Lowercase conversion
2. Punctuation removal
3. Extra whitespace cleanup
4. ASR error correction
5. Unit standardization

**Example:**
```python
Input: "Court, Twenty-Three  Santim."
Step 1: Lowercase â†’ "court, twenty-three  santim."
Step 2: Punctuation â†’ "court twenty-three santim"
Step 3: Whitespace â†’ "court twenty-three santim"
Step 4: ASR correction â†’ "cod twenty-three santim"
Step 5: Unit standard â†’ "cod twenty-three cm"
Output: "cod 23 cm"
```

---

## ğŸ”Š Noise Profiles

Optimize performance for your acoustic environment:

### Profile Comparison

| Profile | Environment | VAD Mode | Suppression | Best For |
|---------|-------------|----------|-------------|----------|
| **clean** | Studio/Office | 1 (Lenient) | Gentle | Quiet environments |
| **human** | Crowded spaces | 2 (Moderate) | Moderate | Background voices |
| **engine** | Vessels/Machinery | 3 (Aggressive) | Strong | Constant noise |
| **mixed** | Variable conditions | 2 (Moderate) | Adaptive | General purpose |

### Detailed Profiles

#### Clean Profile
**Use When:**
- Quiet office environment
- Studio recording
- Minimal background noise

**Settings:**
```python
vad_mode: 1          # Lenient voice detection
suppression: 0.3     # Gentle noise reduction
frame_duration: 30ms # Standard frame size
```

#### Human Profile
**Use When:**
- Crowded fish markets
- Multiple people talking
- Background conversations

**Settings:**
```python
vad_mode: 2          # Moderate voice detection
suppression: 0.5     # Moderate noise reduction
highpass_cutoff: 200Hz # Remove low rumble
```

#### Engine Profile
**Use When:**
- Fishing vessels
- Engine rooms
- Constant machinery noise

**Settings:**
```python
vad_mode: 3          # Aggressive voice detection
suppression: 0.7     # Strong noise reduction
highpass_cutoff: 300Hz # Aggressive low-cut
```

#### Mixed Profile (Default)
**Use When:**
- Variable conditions
- Outdoor environments
- Unknown noise levels

**Settings:**
```python
vad_mode: 2          # Balanced detection
suppression: adaptive # Adapts to noise floor
min_speech: 0.5s     # Minimum segment length
max_segment: 4.0s    # Maximum segment length
```

### Configuring Noise Profiles

**Via GUI:**
1. Open Settings tab
2. Select "Noise Profile" dropdown
3. Choose appropriate profile
4. Click "Apply"

**Via Configuration File:**
```json
{
  "speech": {
    "noise_profile": "engine"
  }
}
```

**Via Environment Variable:**
```bash
export NOISE_PROFILE=engine
```

---


---

## ğŸ“Š Evaluation Pipeline

Comprehensive ASR engine benchmarking system for data-driven model selection.

### Overview

The evaluation pipeline enables:
- **Multi-model comparison**: Test multiple ASR engines simultaneously
- **Reproducible results**: Deterministic evaluation with full configuration tracking
- **Production simulation**: Replay mode mimics real-world segmentation
- **Rich metrics**: WER, CER, DER, exact match, MAE, and latency
- **Visualization**: Automated charts and reports

### Quick Start

```bash
# Run evaluation with default configuration
python -m evaluation.run_evaluation

# Run with limited samples (smoke test)
python -m evaluation.run_evaluation --max-samples 10

# Enable production replay mode
python -m evaluation.run_evaluation --production-replay

# Use custom configuration
python -m evaluation.run_evaluation --model-specs custom_specs.json
```

### Configuration

#### Model Specifications (`evaluation/presets/model_specs.json`)

```json
{
  "dataset_json": "tests/data/numbers.json",
  "audio_root": "tests/audio",
  "concat_number": true,
  "production_replay": false,
  "model_specs": [
    {
      "name": "faster-whisper",
      "sizes": ["tiny.en", "base.en", "small.en"],
      "compute_types": ["int8", "float16"],
      "beam_sizes": [1, 5]
    },
    {
      "name": "whisperx",
      "sizes": ["base.en"],
      "compute_types": ["float16"]
    },
    {
      "name": "vosk",
      "models": ["vosk-model-small-en-us-0.15"]
    }
  ]
}
```

#### Dataset Format (`tests/data/numbers.json`)

```json
{
  "samples": [
    {
      "audio_file": "audio/sample1.wav",
      "expected_text": "twenty three",
      "expected_number": 23,
      "metadata": {
        "speaker": "male",
        "noise_level": "clean"
      }
    }
  ]
}
```

### Evaluation Modes

#### Standard Mode (Default)
- Full audio files processed at once
- Fastest evaluation
- Good for model comparison

#### Production Replay Mode
- Simulates real-time segmentation
- Uses WebRTC VAD + noise controller
- Slower but realistic performance measurement

```bash
python -m evaluation.run_evaluation --production-replay
```

### Metrics Explained

| Metric | Description | Range | Best |
|--------|-------------|-------|------|
| **WER** | Word Error Rate | 0-100% | Lower |
| **CER** | Character Error Rate | 0-100% | Lower |
| **DER** | Digit Error Rate | 0-100% | Lower |
| **Exact Match** | Perfect predictions | 0-100% | Higher |
| **MAE** | Mean Absolute Error (numbers) | 0+ | Lower |
| **Latency** | Processing time (ms) | 0+ | Lower |
| **Memory** | Peak RAM usage (MB) | 0+ | Lower |

### Output Artifacts

```
evaluation_outputs/
â””â”€â”€ eval_2025-10-21_14-30-15/
    â”œâ”€â”€ results.parquet           # Raw results (columnar)
    â”œâ”€â”€ results.xlsx               # Excel spreadsheet
    â”œâ”€â”€ summary_statistics.json    # Aggregated metrics
    â”œâ”€â”€ config.json                # Full run configuration
    â””â”€â”€ plots/
        â”œâ”€â”€ wer_comparison.png     # WER by model
        â”œâ”€â”€ latency_distribution.png
        â”œâ”€â”€ accuracy_vs_speed.png
        â””â”€â”€ confusion_matrix.png
```

### Results Analysis

#### View Results

```python
import pandas as pd

# Load results
df = pd.read_parquet("evaluation_outputs/latest/results.parquet")

# Filter by model
whisper_results = df[df['model_name'] == 'faster-whisper']

# Calculate statistics
print(df.groupby('model_name')['wer'].describe())

# Plot comparisons
import seaborn as sns
sns.boxplot(data=df, x='model_name', y='wer')
```

#### Command Line Analysis

```bash
# Generate summary report
python -m evaluation.visualization \
    --results evaluation_outputs/latest/results.parquet \
    --output report.html

# Compare two runs
python -m evaluation.visualization \
    --compare run1/results.parquet run2/results.parquet
```

### Extending the Pipeline

#### Add New Model

1. Create recognizer class in `speech/`
2. Register in factory:
```python
# speech/factory.py
from speech.my_recognizer import MyRecognizer

RecognizerRegistry.register(
    name="my-model",
    factory=MyRecognizer,
    description="My custom ASR model"
)
```

3. Add to evaluation config:
```json
{
  "model_specs": [
    {
      "name": "my-model",
      "param1": ["value1", "value2"]
    }
  ]
}
```

#### Add New Metric

```python
# evaluation/metrics.py
def my_custom_metric(hypothesis: str, reference: str) -> float:
    """Calculate custom metric."""
    # Implementation
    return score

# evaluation/pipeline.py
from evaluation.metrics import my_custom_metric

# Add to metric computation
metrics["my_metric"] = my_custom_metric(hyp, ref)
```

---

## ğŸ› ï¸ Development

### Development Setup

```bash
# Install development dependencies
# Optional and recommended, do these in virtual environment.
pip install -r requirements.txt 
pip install pytest pytest-cov black isort mypy pylint

# Install pre-commit hooks
pip install pre-commit
pre-commit install
```

### Code Style

**Formatting:**
```bash
# Format code
black .

# Sort imports
isort .

# Combined
black . && isort .
```

**Linting:**
```bash
# Type checking
mypy .

# Linting
pylint app/ parser/ speech/

# Combined
mypy . && pylint app/ parser/ speech/
```

### Project Structure

```
fish-logging/
â”œâ”€â”€ app/                    # Application layer
â”‚   â”œâ”€â”€ application.py      # Main app class
â”‚   â”œâ”€â”€ startup.py          # App initialization
â”‚   â”œâ”€â”€ services.py         # Service layer
â”‚   â””â”€â”€ use_cases.py        # Business logic
â”œâ”€â”€ gui/                    # Presentation layer
â”‚   â”œâ”€â”€ MainWindow.py       # Main window
â”‚   â”œâ”€â”€ table_manager.py    # Table operations
â”‚   â”œâ”€â”€ speech_event_handler.py
â”‚   â”œâ”€â”€ status_presenter.py
â”‚   â””â”€â”€ widgets/            # UI components
â”œâ”€â”€ parser/                 # Domain layer (core logic)
â”‚   â”œâ”€â”€ parser.py               # Main FishParser
â”‚   â”œâ”€â”€ species_matcher.py      # Species recognition
â”‚   â”œâ”€â”€ number_parser.py        # Number extraction
â”‚   â”œâ”€â”€ text_normalizer.py      # Text cleaning
â”‚   â”œâ”€â”€ text_utils.py           # Text utilities
â”‚   â””â”€â”€ config.py               # Parser configuration
â”œâ”€â”€ speech/                  # Infrastructure (ASR)
â”‚   â”œâ”€â”€ base_recognizer.py      # Abstract base class
â”‚   â”œâ”€â”€ factory.py              # Recognizer factory
â”‚   â”œâ”€â”€ faster_whisper_recognizer.py
â”‚   â”œâ”€â”€ whisperx_recognizer.py
â”‚   â”œâ”€â”€ vosk_recognizer.py
â”‚   â”œâ”€â”€ google_speech_recognizer.py
â”‚   â”œâ”€â”€ assemblyai_recognizer.py
â”‚   â”œâ”€â”€ gemini_recognizer.py
â”‚   â”œâ”€â”€ wav2vec2_recognizer.py
â”‚   â”œâ”€â”€ insanely_faster_whisper.py
â”‚   â””â”€â”€ noise_profiles.py       # Noise configuration
â”œâ”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ config.py               # Config data classes
â”‚   â”œâ”€â”€ service.py              # Config facade
â”‚   â”œâ”€â”€ species.json            # Species database
â”‚   â”œâ”€â”€ numbers.json            # Number mappings
â”‚   â”œâ”€â”€ units.json              # Unit definitions
â”‚   â”œâ”€â”€ asr_corrections.json    # ASR corrections
â”‚   â”œâ”€â”€ google_sheets.json      # Sheets credentials
â”‚   â””â”€â”€ user_settings.json      # User preferences
â”œâ”€â”€ logger/                  # Logging infrastructure
â”‚   â”œâ”€â”€ excel_logger.py         # Excel file output
â”‚   â””â”€â”€ session_logger.py       # Session tracking
â”œâ”€â”€ noise/                   # Audio processing
â”‚   â”œâ”€â”€ controller.py           # Noise pipeline
â”‚   â”œâ”€â”€ simple_controller.py    # Simplified version
â”‚   â””â”€â”€ suppressor.py           # Noise suppression
â”œâ”€â”€ services/                # External services
â”‚   â”œâ”€â”€ audio_saver.py          # Audio segment storage
â”‚   â””â”€â”€ google_sheets_backup.py # Cloud backup
â”œâ”€â”€ core/                    # Core utilities
â”‚   â”œâ”€â”€ container.py            # DI container
â”‚   â”œâ”€â”€ exceptions.py           # Custom exceptions
â”‚   â”œâ”€â”€ error_handler.py        # Error handling
â”‚   â””â”€â”€ result.py               # Result types
â”œâ”€â”€ evaluation/              # Testing & benchmarking
â”‚   â”œâ”€â”€ pipeline.py             # Evaluation orchestrator
â”‚   â”œâ”€â”€ config.py               # Evaluation config
â”‚   â”œâ”€â”€ metrics.py              # Metric calculations
â”‚   â”œâ”€â”€ normalization.py        # Text normalization
â”‚   â”œâ”€â”€ visualization.py        # Result plotting
â”‚   â”œâ”€â”€ run_evaluation.py       # CLI runner
â”‚   â”œâ”€â”€ README_TEST_EVAL.md     # Evaluation docs
â”‚   â”œâ”€â”€ datasets/               # Test datasets
â”‚   â””â”€â”€ presets/
â”‚       â””â”€â”€ model_specs.json    # Model configurations
â”‚
â”œâ”€â”€ reports/                 # Report generation
â”‚   â”œâ”€â”€ length_distribution_report.py
â”‚   â””â”€â”€ output/                 # Generated reports
â”‚
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ test_core.py
â”‚   â”œâ”€â”€ test_use_cases.py
â”‚   â”œâ”€â”€ test_speech_factory.py
â”‚   â”œâ”€â”€ test_config_service.py
â”‚   â”œâ”€â”€ number_parser_test.py
â”‚   â”œâ”€â”€ test_numbers_integration.py
â”‚   â”œâ”€â”€ test_noise_profiles.py
â”‚   â”œâ”€â”€ test_evaluation_pipeline.py
â”‚
â”œâ”€â”€ logs/                    # Output logs
â”‚   â”œâ”€â”€ hauls/                  # Excel haul logs
â”‚   â””â”€â”€ sessions/               # Session logs
â”‚
â”œâ”€â”€ audio/                   # Audio data
â”‚   â”œâ”€â”€ evaluation/             # Evaluation audio
â”‚   â””â”€â”€ segments/               # Saved segments (optional)
â”‚
â”œâ”€â”€ assets/                  # Static assets
â”‚   â”œâ”€â”€ bg.jpg                  # Background image
â”‚   â”œâ”€â”€ audio/                  # Audio assets
â”‚   â””â”€â”€ icons/                  # Application icons
â”‚
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ add_noise.py            # Audio augmentation
â”‚   â”œâ”€â”€ generate_dataset_json.py
â”‚   â””â”€â”€ realtime_clean_wav.py
â”‚
â””â”€â”€ evaluation_outputs/      # Evaluation results
    â””â”€â”€ eval_YYYYMMDD_HHMMSS/   # Timestamped runs
```

### Key Files Explained

| File | Purpose |
|------|---------|
| `main.py` | Application entry point, initializes and starts app |
| `app/application.py` | Main application class managing lifecycle |
| `app/use_cases.py` | Business logic separated from UI |
| `gui/MainWindow.py` | Main GUI window coordinating UI components |
| `parser/parser.py` | Core parsing logic for fish entries |
| `speech/factory.py` | Factory for creating ASR recognizers |
| `config/service.py` | Facade for simplified configuration access |
| `evaluation/pipeline.py` | Automated ASR benchmarking system |
| `logger/excel_logger.py` | Excel file management and writing |
| `noise/controller.py` | Real-time audio processing pipeline |

---

## ğŸ¤ Adding New Features


### Getting Started

1. **Fork the repository**
2. **Create a feature branch**:
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Make your changes**
4. **Write/update tests**
5. **Run test suite**:
   ```bash
   python run_tests.py
   ```
6. **Format code**:
   ```bash
   black . && isort .
   ```
7. **Commit changes**:
   ```bash
   git commit -m "Add: description of your changes"
   ```
8. **Push to fork**:
   ```bash
   git push origin feature/your-feature-name
   ```
9. **Submit pull request**

### Contribution Types

- ğŸ› **Bug fixes**: Fix issues with existing functionality
- âœ¨ **New features**: Add new capabilities
- ğŸ“š **Documentation**: Improve docs, examples, or guides
- ğŸ§ª **Tests**: Add or improve test coverage
- ğŸ¨ **UI improvements**: Enhance user interface
- âš¡ **Performance**: Optimize speed or resource usage
- â™»ï¸ **Refactoring**: Improve code quality

### Code Standards

- Follow PEP 8 style guide
- Use type hints for function signatures
- Write docstrings for public APIs
- Maintain test coverage >80%
- Keep functions focused and small (<50 lines)
- Use meaningful variable names


---
### Technologies
- **PyQt6**: GUI framework
- **OpenAI Whisper**: Speech recognition models
- **faster-whisper**: Optimized Whisper inference
- **WebRTC VAD**: Voice activity detection
- **RapidFuzz**: Fuzzy string matching
- **Pandas**: Data manipulation
- **Loguru**: Logging framework
---



Made by Ali Altun in his internship, 08/2025 - 10/2025. 